{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donders Sessions Data Visualization - EEG/MEG workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures play a central role in the communication of research findings from scientific studies. Therefore, it is important that they accurately represent the underlying data. However, visualizations can be misleading and graphical design choices can bias perceptions (e.g. check out [this blogpost from Flowing Data](https://flowingdata.com/2017/02/09/how-to-spot-visualization-lies/)). This workshop aims to promote critical thinking about visualizing scientific data and provides you with tools and advise that will help you make better figures. More specifically, you will:\n",
    "1. evaluate figures from the neuroscience literature;\n",
    "2. see how data visualization complements statistical testing;\n",
    "3. experience how certain graph types are easier to decode than others;\n",
    "4. learn how you may improve visualization of 2D data;\n",
    "5. learn how you may improve visualization of 3D EEG/MEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%python \n",
    "from IPython.display import HTML, IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluating figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2012 survey of 1451 figures from 288 studies in top neuroscience journals found that scientific figures are often unclear and incomplete (Allen et al., 2012). This survey categorized each figure as 2D (e.g. bar, scatter, and line graphs) or 3D (e.g. fMRI statistical maps, time-frequency plots) and answered four questions:\n",
    "1. Is the dependent variable labeled?\n",
    "2. Is the scale of the dependent variable indicated? \n",
    "3. Where applicable, is a measure of uncertainty displayed?\n",
    "4. Is the type of uncertainty (e.g. standard error of the mean) defined in the figure or legend?\n",
    "\n",
    "The figure below shows the survey's results: as compared to displays of 2D data, visualizations of 3D data often lack labels and rarely depict measures of uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"950\"\n",
       "            height=\"300\"\n",
       "            src=\"./data/1_Allen_et_al_2012_FigS1A_Survey_results_by_journal.jpeg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1e128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame('./data/1_Allen_et_al_2012_FigS1A_Survey_results_by_journal.jpeg',width= 950, height= 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Survey results separated by journal__. (A) Mean proportion of 2D (white) and 3D (dark gray) figures displaying each feature. Error bars denote 95% non-parametric confidence intervals (10,000 resamples). NN = Nature Neuroscience; NE = Neuron; JN = Journal of Neuroscience; FSN = Frontiers in Systems Neuroscience; NI = Neuroimage; HBM = Human Brain Mapping. \n",
    "\n",
    "_Source_: Allen, E. A., Erhardt, E. B., & Calhoun, V. D. (2012). Data Visualization in the Neurosciences: Overcoming the Curse of Dimensionality. Neuron, 74(4), 603–608. https://doi.org/10.1016/j.neuron.2012.05.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<b>EXERCISE 1</b> <br>\n",
    "\n",
    "You will evaluate one or more figures from recent fMRI studies for clarity and completeness. These figures were published in _Journal of Neuroscience_ and _Cerebral Cortex_. You can guide your evaluation by the four questions above and the more comprehensive checklist below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"1050\"\n",
       "            src=\"./data/checklist_scientific_figures.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1e5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame('./data/checklist_scientific_figures.pdf',width= 800, height= 1050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Case 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"425\"\n",
       "            src=\"./data/1_1_Fazli_Fig4.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1e668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/1_1_Fazli_Fig4.png\", width= 800, height= 425)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig. 4.__ Scalp evolution of grand-average log p values for motor execution in EEG and NIRS over all subjects (top: EEG, middle: [HbO], bottom: [HbR]). Red colors denote higher values of the left class, while blue colors indicate higher values within the right class. Note that the width of the color-scale on the right indicates the level of significance.\n",
    "\n",
    "_Source_: Fazli, S., Mehnert, J., Steinbrink, J., Curio, G., Villringer, A., Müller, K.-R., Blankertz, B. (2012). Enhanced performance by a hybrid NIRS–EEG brain computer interface. NeuroImage, 59, 519-529. https://doi.org/10.1016/j.neuroimage.2011.07.084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"525\"\n",
       "            src=\"./data/1_1_Harris_Fig_5.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1e748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/1_1_Harris_Fig_5.png\", width=800, height=525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig. 5.__ Lateralization of non-phase-locked alpha amplitude for Experiment 1. A. Scalp topographies showing the distribution of non-phase-locked alpha amplitude averaged over the period from 406 ms to 469 ms post-cue onset. Topographies are presented relative to a target on the left (right-side target trials have had their topography flipped). Thus, in these topographies, ‘same side’ refers to a cue on the left, and ‘opposite sides’ refers to a cue on the right. White dots represent analyzed electrodes. B and C, Non-phase-locked alpha lateralization index data for trials in which the cue and target appeared in the same visual hemifield (solid colored lines) or in opposite hemifields (dashed colored lines), and for no-cue trials (solid gray lines). Green lines indicate target matching cue trials. Blue lines indicate non-target matching cue trials. No-cue responses are identical in both plots. Positive numbers indicate greater alpha amplitude ipsilateral the target side. Negative values indicate greater alpha amplitude contralateral the target side. Solid black lines along the x-axis represent significant lateralization differences between Same Side and Opposite Side cue responses (p < .05), adjusted to control the false discovery rate (Benjamini and Hochberg, 1995). Error shading represents one within-participant SEM (Cousineau, 2005; Morey, 2008).\n",
    "\n",
    "_Source_: Harris, A.M., Dux, P.E., Jones, C.N., Mattingley, J.B. (2017). Distinct roles of theta and alpha oscillations in the involuntary capture of goal-directed attention. NeuroImage 152, 171-183. http://dx.doi.org/10.1016/j.neuroimage.2017.03.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500\"\n",
       "            height=\"1200\"\n",
       "            src=\"./data/1_1_Lewis_Fig3.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ea90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/1_1_Lewis_Fig3.jpg\", width=500, height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig. 3.__ Signal and noise correlations. (A) Signal correlation matrix in the gamma band (80–95 Hz) for all V1–V4 site pairs. (B) Distribution of signal correlation values for all interareal site pairs as a function of frequency. (C) Noise correlation matrix in the same band as in A. (D) Distribution of noise correlation values as a function of frequency. (E) Correlation of interareal signal and noise correlation matrices (A and C) across frequencies. Frequency–frequency plane threshold P < 0.05 corrected for multiple comparisons. Significance threshold is denoted on color bar by red line and value.\n",
    "\n",
    "_Source_: Lewis, C.M., Bosman, C.A., Womelsdorf, T., Fries, P. (2016). Stimulus-induced visual cortical networks are\n",
    "recapitulated by spontaneous local and interareal synchronization. PNAS 113(5), 606-615.\n",
    "https://doi.org/10.1073/pnas.1513773113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"425\"\n",
       "            src=\"./data/1_1_Marshall_Fig3.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1eb38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/1_1_Marshall_Fig3.png\", width=800, height=425)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig. 3__. A, moving annulus stimulus induces a strong gamma-band power increase that is robustly detectable in all tDCS conditions and localisable to visual cortex. MNI axial slice coordinates 38, 14, −10, −34. B, moving annulus induces strong alpha-band desynchronisation in all tDCS conditions. Slice co-ordinates as A. C, time-resolved virtual sensor analysis reveals\n",
    "comparable gamma-band increase (top row) and alpha-band decrease (bottomrow) during visual stimulus processing in all tDCS conditions. Grey bars indicate the time interval the visual stimulus was on screen. D, power spectra of the visual stimulus-induced power changes for each tDCS condition. Shaded bars indicate ±1 standard error of the mean.\n",
    "\n",
    "_Source_: Marshall, T.R., Esterer, S., Herring, J.D., Bergmann, T.O., Jensen, O. (2016). On the relationship between cortical excitability and visual oscillatory responses — A concurrent tDCS–MEG study. NeuroImage 140, 41-49. \n",
    "http://dx.doi.org/10.1016/j.neuroimage.2015.09.069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Take home message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing and reviewing figures, carefully think about the design and your audience. Also, try out your figures on colleagues who are not directly involved in your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allen, E. A., Erhardt, E. B., & Calhoun, V. D. (2012). Data Visualization in the Neurosciences: Overcoming the Curse of Dimensionality. Neuron, 74(4), 603–608. https://doi.org/10.1016/j.neuron.2012.05.001\n",
    "- Allen, E. A., & Erhardt, E. B. (2017). Visualizing Scientific Data. In J. T. Cacioppo, L. G. Tassinary, & G. G. Berntson (Eds.), Handbook of Psychophysiology (4th ed., pp. 679–697). Cambridge: Cambridge University Press. https://doi.org/10.1017/9781107415782.031\n",
    "- Tufte, E. R. (1983). The Visual Display of Quantitative Information (1st edition). Graphics Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why visualize your data anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the hands-on part, startup MATLAB 2016b (__Start -> All Programs -> MATLAB R2016b -> MATLAB R2016b__) and run the following code to ensure that all paths are set correctly and all relevant directories are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Define some directories\n",
    "workshop_dir = 'h:\\common\\temporary\\donders_data_visualization_workshop';\n",
    "data_dir     = fullfile(workshop_dir,'data','workshop_eeg');\n",
    "\n",
    "% Provide access to MATLAB and SPM\n",
    "addpath('h:\\common\\matlab\\spm12');\n",
    "\n",
    "% Provide access to a few toolboxes we are going to use\n",
    "addpath(genpath(fullfile(workshop_dir,'opt','gramm')))\n",
    "addpath(genpath(fullfile(workshop_dir,'opt','panel-2.12')))\n",
    "\n",
    "% Provide access to the code written for this workshop\n",
    "addpath(genpath(fullfile(workshop_dir,'src','code','workshop_eeg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to communicating research findings, another purpose of data visualization is to guide data exploration. A common data analysis mistake is to skip data exploration and to immediately perform statistical tests and look of statistical significance. This happens especially when automated software and processing pipelines are in place. However, it is essential to visually inspect your data first, as it will help you to:\n",
    "- understand broad features of the data;\n",
    "- inspect the qualitative features of the data;\n",
    "- discover new or unexpected patterns in the data.\n",
    "\n",
    "In fact, graphics can be more revealing than typical statistical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. What you will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the importance of data visualization in exploratory analysis, you will analyze a dataset known as Anscombe's quartet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. The data: Anscombe's quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anscombe's quartet consists of four sets of x-y pairs. As you will see, descriptive statistics and statistical testing appears to suggest that these four sets are extremely similar, if not identical. However, simply plotting the data reveals that they are very different and that some of them violate the assumptions underlying the statistical tests employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. The tool: gramm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[gramm](https://github.com/piermorel/gramm) is a MATLAB toolbox for data visualization that allows you to create a wide range of simple and more complex graphs. Gramm is based on [R's ggplot2 library](http://ggplot2.org/), which in turn was inspired by Leland Wilkinson's book [The Grammar of Graphics](https://www.amazon.de/Grammar-Graphics-Statistics-Computing/dp/1441920331/ref=sr_1_1?ie=UTF8&qid=1489520946&sr=8-1&keywords=wilkinson+%22grammar+of+graphics%22)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Anscombe's quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Anscombe's quartet - impressions from descriptive and inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the dataset and compute some descriptive statistics. Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Load Anscombe's quartet dataset\n",
    "load(fullfile(data_dir,'anscombe.mat'))\n",
    "\n",
    "% 1. Number of observations (x,y-pairs)\n",
    "fprintf(1, '01. Number of observations (x,y-pairs) \\n Set 1: %.0f \\n Set 2: %.0f \\n Set 3: %.0f \\n Set 4: %.0f \\n', ... \n",
    "        numel(anscombe.x1), ...\n",
    "        numel(anscombe.x2), ...\n",
    "        numel(anscombe.x3), ...\n",
    "        numel(anscombe.x4));\n",
    "\n",
    "% 2. Mean of X's in each set\n",
    "fprintf(1, '02. Mean of X''s in each set \\n Set 1: %.2f \\n Set 2: %.2f \\n Set 3: %.2f \\n Set 4: %.2f \\n', ... \n",
    "        mean([anscombe.x1;anscombe.x2;anscombe.x3;anscombe.x4],2));\n",
    "\n",
    "% 3. Mean of Y's in each set\n",
    "fprintf(1, '03. Mean of Y''s in each set \\n Set 1: %.2f \\n Set 2: %.2f \\n Set 3: %.2f \\n Set 4: %.2f \\n', ... \n",
    "        mean([anscombe.y1;anscombe.y2;anscombe.y3;anscombe.y4],2));\n",
    "\n",
    "% 4. Linear regression coefficients\n",
    "fprintf(1, '04. Linear regression coefficients (intercept, slope) in each set \\n Set 1: %.2f, %.2f \\n Set 2: %.2f, %.2f \\n Set 3: %.2f, %.2f \\n Set 4: %.2f, %.2f \\n', ... \n",
    "        regress(anscombe.y1',[ones(11,1) anscombe.x1']), ...\n",
    "        regress(anscombe.y2',[ones(11,1) anscombe.x2']), ...\n",
    "        regress(anscombe.y3',[ones(11,1) anscombe.x3']), ...\n",
    "        regress(anscombe.y4',[ones(11,1) anscombe.x4']));\n",
    "\n",
    "% 5. Sum of squares\n",
    "fprintf(1, '05. Sum of squares of X''s in each set \\n Set 1: %.2f \\n Set 2: %.2f \\n Set 3: %.2f \\n Set 4: %.2f \\n', ... \n",
    "        sum((anscombe.x1 - mean(anscombe.x1)).^2), ...\n",
    "        sum((anscombe.x2 - mean(anscombe.x2)).^2), ...\n",
    "        sum((anscombe.x3 - mean(anscombe.x3)).^2), ...\n",
    "        sum((anscombe.x4 - mean(anscombe.x4)).^2));\n",
    "\n",
    "% 6. Correlation coefficients\n",
    "fprintf(1, '06. Correlation coefficients in each set \\n Set 1: %.2f \\n Set 2: %.2f \\n Set 3: %.2f \\n Set 4: %.2f \\n', ... \n",
    "        corr(anscombe.x1',anscombe.y1','type','pearson'), ...\n",
    "        corr(anscombe.x2',anscombe.y2','type','pearson'), ...\n",
    "        corr(anscombe.x3',anscombe.y3','type','pearson'), ...\n",
    "        corr(anscombe.x4',anscombe.y4','type','pearson'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that from the perspective of descriptive statistics, the four sets look highly similar, if not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Anscombe's quartet - impressions from graphical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, display the x-y relationships for the very same datasets. Run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear g \n",
    "\n",
    "% Scatter of set 1\n",
    "g(1,1)=gramm('x',anscombe.x1,'y',anscombe.y1);\n",
    "g(1,1).set_names('x','x1','y','y1');\n",
    "g(1,1).geom_point();\n",
    "\n",
    "% Scatter of set 2\n",
    "g(1,2)=gramm('x',anscombe.x2,'y',anscombe.y2);\n",
    "g(1,2).set_names('x','x2','y','y2');\n",
    "g(1,2).geom_point();\n",
    "\n",
    "% Scatter of set 3\n",
    "g(2,1)=gramm('x',anscombe.x3,'y',anscombe.y3);\n",
    "g(2,1).set_names('x','x3','y','y3');\n",
    "g(2,1).geom_point();\n",
    "\n",
    "% Scatter of set 4\n",
    "g(2,2)=gramm('x',anscombe.x4,'y',anscombe.y4);\n",
    "g(2,2).set_names('x','x4','y','y4');\n",
    "g(2,2).geom_point();\n",
    "\n",
    "g.draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/2_1_Anscombe_quartet.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ebe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/2_1_Anscombe_quartet.jpg\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is immediately clear that four datasets are very different! You might want to know that a somewhat similar quartet exists for ANOVA interaction effects, described by [Wagenmakers](https://dx.doi.org/10.1016/j.cortex.2015.07.031)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Take home message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always plot your data! Graphs are essential to good statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Anscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17. https://doi.org/10.2307/2682899\n",
    "- Wagenmakers, E.-J. (2015). A quartet of interactions. Cortex, 73, 334–335."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Things to consider when designing visualizations: Graphical perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very same dataset can be visualized in many ways (for a nice example, see [this blogpost from Flowing Data](https://flowingdata.com/2017/01/24/one-dataset-visualized-25-ways/#jp-carousel-47350)). The questions in the checklist above are useful to consider when designing your scientific figures. In addition, you may want to take the perceptual capacities of your readers into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. What you will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will experience how certain types of visualizations are more efficiently and more accurately decoded than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you will be displaying is based on [Haemer, 1947](https://doi.org/10.2307/2681528) and [Allen & Erhardt (2017)](https://dx.doi.org/10.1017/9781107415782.031)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. The tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native MATLAB visualization tools used, but all code is under the hood in the function ```graphical_perception```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Decoding information from graphs: visual attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualizations communicate numbers in terms of visual attributes (e.g. color, shape, size) of geometric objects (e.g. bars, lines, points). Communication is effective only if the reader is able to perceptually decode the information. Information stored in graphs can be decoded through several visual operations, or 'elementary perceptual tasks'. For example, judging the shade of a color, judging the volume or area of an object, or judging the position of a point along a common scale. As it turns out, decoding efficiency and accuracy differs between elementary perceptual tasks.\n",
    "\n",
    "You will experience this now yourself. The following figure plots the same seven values (across rows) using six different visual attributes (across columns). Can you sort the rows by magnitude? \n",
    "\n",
    "Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphical_perception('decoding_visual_attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/3_1_decoding_visual_attributes.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ec88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/3_1_decoding_visual_attributes.jpg\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct ordering is C, G, E, B, F, A, D. You may have experienced that sorting is more efficient and accurate for attributes on the right as compared to attributes on the left. Indeed, experiments by William Cleveland and Robert McGill in the 1980s showed that the above elementary perceptual tasks can be ordered as followed (from most to least accurate):\n",
    "1. Position along a common scale\n",
    "2. Length and angle\n",
    "3. Area\n",
    "4. Volume\n",
    "5. Color saturation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Decoding information from graphs: difference between curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also take into account perceptual limitations when visually comparing curves. The following figure plots three panels with two curves each. Can you determine how the difference between curves evolves as a function of x (e.g. increase/deccrease linearly or exponentially, or remains constant)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphical_perception('decoding_differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"320\"\n",
       "            src=\"./data/3_2_visualizing_differences.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ed30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/3_2_visualizing_differences.jpg\", width=800, height=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answers are: difference remains constants (left panel), difference increases linearly (middle panel), and difference increases exponentially. If you are surprised by the answers, consider the following. To determine the difference between curves, we must judge the vertical distance between them. However, our brains tend to judge the minimum distance between the curves, rather than the vertical distance. The upshot is that if the difference between curves is of interest, then plot this directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Take home message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing visualizations, take into account perceptual abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleveland, W. S., Diaconis, P., & Mcgill, R. (1982). Variables on Scatterplots Look More Highly Correlated When the Scales Are Increased. Science, 216(4550), 1138–1141. https://doi.org/10.1126/science.216.4550.1138\n",
    "- Cleveland, W. S., & McGill, R. (1985). Graphical perception and graphical methods for analyzing scientific data. Science, 229(4716), 828–833.\n",
    "- Haemer, K. W. (1947). Hold That Line. A Plea for the Preservation of Chart Scale Rulings. The American Statistician, 1(1), 25. https://doi.org/10.2307/2681528\n",
    "- Heer, J., & Bostock, M. (2010). Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (pp. 203–212). New York, NY, USA: ACM. https://doi.org/10.1145/1753326.1753357\n",
    "- Lewandowsky, S., & Spence, I. (1989). Discriminating Strata in Scatterplots. Journal of the American Statistical Association, 84(407), 682–688. https://doi.org/10.1080/01621459.1989.10478821"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing low-dimensional data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Anscombe’s quartet is a great example to argue for showing all data, the biggest opposition comes in the form of it being too much information. Bar plots, for example, are widely used for their simplicity. They tell a story that’s easy to understand and compare, one may say. But, as you will see, bar plots are not without problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. What you will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will visualize a very simple dataset using a bar plot, box plot, and violin plot. As we go along, you will see that the richness of the display increases and your impression about the underlying data may change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. The data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with a mock dataset from Allen et al., (2012). This dataset consists of 50 samples of a continuous response variable collected under three conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. The tool: gramm\n",
    "The visualization tool used is [gramm](https://github.com/piermorel/gramm), but all code is under the hood in the script ```simple_plot```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Showing more, hiding less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Bar plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data first using a __bar plot__. Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_plot('barplot',data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/4_2_1_bar_plot.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1edd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/4_2_1_bar_plot.jpg\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot displays the sample mean and standard error. Bar plots have the following strengths:\n",
    "- easy to generate and comprehend;\n",
    "- can efficiently contrast a large number of conditions in a small space;\n",
    "- effective for displaying frequencies or proportions.\n",
    "\n",
    "However, bar plots are not without problems. They reveal very little about the distribution of data and can therefore be misleading (for a great example and funny initiative, see [the #barbarplots Kickstarter project](https://www.kickstarter.com/projects/1474588473/barbarplots)). In fact, bar plots are only suitable for visualizing a set of counts or proportions (e.g. [Krzywinski & Altman, 2014](https://dx.doi.org/10.1038/nmeth.2813)).\n",
    "\n",
    "The bar graph appears to suggest that the conditions have a similar effect on the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize the same data first using a __box plot__. Run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple_plot('boxplot',data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/4_2_2_box_plot.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ee80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/4_2_2_box_plot.jpg\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, box plots provide a richer view of the data: \n",
    "- the line inside the box displays the __median__; \n",
    "- the bottom and top of the box show the __first and third quartiles__;\n",
    "- the whiskers show the __lowest and highest data point still within 1.5 IQR of the lower and higher quartiles__, respectively;\n",
    "- the dots show __outlying values__ (i.e. beyond 1.5 times the interquartile range), if any.\n",
    "\n",
    "Furthermore, notice that this figure now shows the range of the data and that the response values could take both positive and negative values! Such information is just hidden from your reader if you only plot the means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Violin plots with data superimposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the same data again with a __violin plot__ with superimposed the actual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_plot('violinplot',data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/4_2_3_violin_plot.jpg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame object at 0x109d1ef28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "IFrame(\"./data/4_2_3_violin_plot.jpg\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot is somewhat similar to a box plot in that it displays the distribution of the data. It goes beyond a box pot, because it also shows the probability density of the data at different values.\n",
    "\n",
    "The violin plot reveals differences in distributions across the three conditions and suggests that assumption of normality (required for parameteric analyses such as ANOVA) is violated under conditions 2 and 3: under condition 2 the distribution is heavy-tailed, whereas under condition 3 it is bimodal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Take home message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show more, hide less; plot as much of the actual data as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kampstra, P. (2008). Beanplot: A Boxplot Alternative for Visual Comparison of Distributions. Journal of\n",
    "Statistical Software, 28(Code Snippet 1), 1 - 9. doi: http://dx.doi.org/10.18637/jss.v028.c01\n",
    "- Rousselet, G. A., Foxe, J. J., & Bolam, J. P. (2016). A few simple steps to improve the description of group results in neuroscience. European Journal of Neuroscience. https://doi.org/10.1111/ejn.13400\n",
    "- Yau, Nathan. \"How to Visualize and Compare Distributions.\" FlowingData. Retrieved March 14, 2017, from\n",
    "http://flowingdata.com/2012/05/15/how-to-visualize-and-compare-distributions/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
